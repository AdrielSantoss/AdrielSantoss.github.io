<!DOCTYPE html>
<html lang="pt-br">
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>Entendendo algoritmos de diff</title>
        <link rel="stylesheet" href="../../../assets/css/style.css" />
        <link rel="stylesheet" href="../../../assets/css/changes.css" />
    </head>
    <body>
        <main class="main-body">
            <div class="main-content">
                <article>
                    <section>
                        <h1 class="h4 portfolio-title">Entendendo algoritmos de diff de texto</h1>
                        <div>
                            <small style="color: white">17/10/2025</small> -
                            <a
                                href="https://github.com/AdrielSantoss/Myers-Patience-Diff"
                                target="_blank"
                                class="blog-link"
                                >Projeto (Github)</a
                            >
                        </div>
                        <div class="tags">
                            <small class="tag">Algoritmo</small>
                            <small class="tag">Programação dinâmica</small>
                            <small class="tag">Rust</small>
                            <small class="tag">Diff</small>
                            <small class="tag">Compressão</small>
                            <small class="tag">Git</small>
                        </div>
                    </section>

                    <section class="portfolio-description">
                        <div id="intro" class="about-text">
                            <p>
                                Neste artigo, vou falar sobre algoritmos de diff e, de quebra, um pouco sobre
                                compressão. Desenvolvi um sistema em Rust que implementa dois algoritmos de diff:
                                <strong>Myers</strong> e <strong>Patience</strong>.
                            </p>
                            <p>
                                O projeto nasceu com o objetivo de integrá-lo ao GitAdr. Escolhi Rust por preferência
                                pessoal, mas você pode implementar esses algoritmos em qualquer linguagem que desejar.
                            </p>
                            <p>
                                Além da integração com o GitAdr, um dos motivos da criar esse projeto, é que no
                                trabalho, atualmente eu utilizo Windows 11, e por padrão, o Windowes não possui nenhuma
                                ferramenta de diff decente, todas são simples de força bruta de comparação linha a
                                linha, nenhuma baseada no algoritmo do Myers.
                            </p>
                            <p>
                                E, claro, um dos principais motivos para criar este projeto foi a oportunidade de
                                aprender mais sobre algoritmos de diff de texto.
                            </p>
                        </div>
                        <div id="history" class="about-text">
                            <h1 class="h4 portfolio-title">Estudar o passado é compreender o presente</h1>

                            <p>
                                O primeiro algoritmo de diff eficiente foi implementado em <strong>1976</strong> para o
                                sistema operacional Unix por <strong>Douglas McIlroy</strong> e
                                <strong>James Hunt</strong> na Bell Labs — assim que surgiu a ferramenta diff que existe
                                em todo Linux atualmente.
                            </p>
                            <p>
                                Essa ferramenta de diff realiza comparação por <strong>linha</strong> e utiliza o
                                algoritmo
                                <a
                                    href="https://en.wikipedia.org/wiki/Longest_common_subsequence"
                                    target="_blank"
                                    class="blog-link"
                                    >Longest common subsequence (LCS)</a
                                >, esse algoritmo possui complexidade: <strong>O(n × m)</strong> de tempo e memória.
                                Sendo <strong>n</strong> o tamanho (número de linhas) do primeiro arquivo e
                                <strong>m</strong> o tamanho do segundo arquivo.
                            </p>
                            <p>
                                Após o surgimento e popularização do diff baseado em LCS, surgiu o comando
                                <code>patch</code> criado por Larry Wall (o mesmo criador do Perl). Esse comando
                                permitia aplicar um arquivo .diff (também chamado .patch) para reconstruir a nova versão
                                de um arquivo.
                            </p>
                            <p>Isso criou o ciclo clássico:</p>
                            <pre><code>diff old new > changes.patch 
patch old < changes.patch</code></pre>
                            <p>
                                Esse mecanismo se tornou fundamental para o desenvolvimento colaborativo de software
                                livre (BSD, GNU, etc.).
                            </p>
                            <p>
                                É importante destacar que o algoritmo de LCS utiliza
                                <strong>programação dinâmica</strong> para resolver o problema. Programação dinâmica é
                                uma técnica para resolver problemas complexos dividindo-os em subproblemas menores e
                                reaproveitando resultados já calculados. Ou seja, o problema é resolvido por etapas
                                (quase sempre utilizando matrizes, mas isso depende do problema).
                            </p>
                            <p>
                                No caso do algoritmo LCS, a solução envolve criar e percorrer uma matriz de acordo com
                                as linhas dos arquivos que estão sendo comparados. Essa é uma matriz m × n (m = tamanho
                                do arquivo 1, n = tamanho do arquivo 2), com complexidade:
                                <code>Tempo: O(m × n) | Memória: O(m × n)</code>. Isso pode ser viável para textos
                                curtos, mas torna-se completamente inviável para arquivos grandes (por exemplo, milhares
                                de linhas).
                            </p>
                            <p>
                                Em 1986, esse problema de performance foi resolvido por um cientista da computação
                                norte-americano chamado <strong>Eugene W. Myers</strong>, que se tornou muito famoso
                                pelo seu artigo:
                                <a href="http://www.xmailserver.org/diff2.pdf" class="blog-link" target="_blank">
                                    An O(ND) Difference Algorithm and Its Variations </a
                                >. Nesse artigo, Myers apresenta uma otimização da solução do problema de LCS de forma
                                extremamente eficiente.
                            </p>
                            <p>
                                Ele calcula o Shortest Edit Script (SES) diretamente, sem precisar construir toda a
                                matriz da programação dinâmica. A ideia central é representar o processo de edição em um
                                grafo de caminhos de diferença e encontrar o caminho mais curto usando uma abordagem de
                                expansão por diagonais, com complexidade: <strong>Tempo:</strong>
                                <code>O(N × D)</code> e <strong>Memória:</strong> <code>O(N + M)</code>, onde N e M são
                                os tamanhos das duas sequências e D é o número mínimo de edições (inserções + deleções).
                            </p>
                            <p>
                                De forma simplificada, imagine que, em vez de criar uma tabela inteira e percorrê-la até
                                chegar à última célula, o algoritmo de Myers realiza <strong>atalhos</strong>,
                                caminhando apenas pelas diagonais até atingir a última célula da matriz.
                            </p>
                            <p>
                                Para entender melhor, veja este exemplo visual de uma matriz sendo percorrida pelo
                                algoritmo LCS:
                            </p>

                            <pre><code>
arquiv0_A = "ABCABBA"
arquivo_B = "CBABAC"

    C     B     A    B    A     C
    +---+---+---+---+---+---+---+--+
A | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |
B | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |
C | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |
A | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |
B | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |
B | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |
A | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |

Total: 7 × 6 = 42 operações
Ou seja, ele percorre toda a matriz.
</code></pre>
                            <p>Agora visualize o trajeto do algoritmo Myers resolvendo o mesmo problema:</p>
                            <pre><code>
arquiv0_A = "ABCABBA"
arquivo_B = "CBABAC"

    C     B     A    B    A     C
    +---+---+---+---+---+---+---+--+
A | ⬛ | ⬛ | ✅ | ⬛ | ⬛ | ⬛ |
B | ⬛ | ✅ | ✅ | ✅ | ⬛ | ⬛ |
C | ✅ | ✅ | ⬛ | ⬛ | ⬛ | ✅ |
A | ⬛ | ✅ | ✅ | ⬛ | ✅ | ⬛ |
B | ⬛ | ✅ | ✅ | ✅ | ⬛ | ⬛ |
B | ⬛ | ⬛ | ✅ | ✅ | ✅ | ⬛ |
A | ⬛ | ⬛ | ✅ | ✅ | ✅ | ✅ |

✅ = célula realmente explorada.
⬛ = célula ignorada/fora do caminho possível.

Total: aproximadamente 20 células visitadas (em vez de 42)
</code></pre>
                            <p>
                                O objetivo de qualquer algoritmo de diff é gerar o
                                <a href="https://en.wikipedia.org/wiki/Edit_distance" class="blog-link" target="_blank"
                                    >Shortest Edit Script (SES)</a
                                >: O menor conjunto de operações (inserções e deleções) necessárias para transformar uma
                                sequência A em B. Atualmente, o algoritmo de Myers encontra a
                                <strong>solução ótima</strong> para o problema do SES, isto é, resolve o problema de
                                forma mais eficiente possivel, e é amplamente utilizado nas ferramentas de diff modernas
                                até hoje.
                            </p>

                            <p>
                                Atualmente, o algoritmo de <strong>Myers</strong> é o padrão utilizado pelo
                                <strong>Git</strong> para a geração de diffs. Ele também está presente nas principais
                                distribuições Linux, integrado à ferramenta <code>diff</code> do pacote
                                <code>GNU diffutils</code>. Esse módulo inclui, principalmente, os seguintes
                                utilitários:
                            </p>

                            <p>
                                <code>diff:</code> compara dois arquivos ou diretórios e exibe as diferenças linha a
                                linha. (<em>Utiliza o algoritmo de Myers</em>) <br /><br />

                                <code>cmp:</code> compara dois arquivos byte a byte (ou linha a linha), indicando o
                                ponto exato em que diferem. (<em>Não utiliza o algoritmo de Myers</em>) <br /><br />

                                <code>diff3:</code> compara três arquivos — normalmente o “original”, a “versão A” e a
                                “versão B” — e pode gerar uma fusão (<em>merge</em>) com indicação de conflitos. (<em
                                    >Utiliza o algoritmo de Myers</em
                                >) <br /><br />

                                <code>sdiff:</code> compara dois arquivos lado a lado e permite, de forma interativa,
                                escolher ou mesclar alterações. (<em>Utiliza o algoritmo de Myers</em>)
                            </p>

                            <p>
                                Alternativas modernas de Diffs como <strong>Patience Diff</strong> ou
                                <strong>Histogram Diff</strong> aplicam soluções heuristicas, na prática, são pequenas
                                variações do algoritmo LCS, ambos com menos perfomance, mas com maior foco em melhorar a
                                legibilidade do diff.
                            </p>
                            <p>
                                <strong>Sobre o Patience Diff:</strong> foi criado por Bram Cohen (criador do
                                BitTorrent) em 2007. Em 2008, chegou a ser adotado pelo sistema de controle de versão
                                <strong>Bazaar</strong> e, em 2010, a equipe do Git adicionou suporte ao algoritmo por
                                meio da opção <code>--diff-algorithm=patience</code>.
                            </p>
                            <p>
                                Esse algoritmo prioriza a geração de diffs mais <strong>legíveis</strong> para humanos.
                                Ele faz isso detectando <code>anchors</code> (âncoras), que são linhas únicas presentes
                                em ambos os arquivos, e aplica o diff apenas <em>entre</em> essas âncoras. Para
                                identificar essas âncoras, o algoritmo utiliza uma ordenação seguida da resolução do
                                problema da
                                <a
                                    href="https://en.wikipedia.org/wiki/Longest_increasing_subsequence"
                                    class="blog-link"
                                    target="_blank"
                                    ><strong>LIS</strong> (<em>Longest Increasing Subsequence</em> — subsequência
                                    crescente mais longa).</a
                                >.
                            </p>
                            <p>
                                Porém, se nenhuma âncora for encontrada — ou seja, se os arquivos A e B forem
                                extremamente diferentes —, o <em>Patience Diff</em> passa a utilizar o algoritmo de
                                <strong>Myers</strong> como estratégia de fallback. Em condições normais, o
                                <em>Patience Diff</em> possui complexidade de tempo média <code>O(n log n)</code> e
                                complexidade de memória <code>O(n)</code>, mas, ao recorrer ao algoritmo de Myers, a
                                complexidade pode chegar a <code>O(n × m)</code> tanto em tempo quanto em uso de
                                memória.
                            </p>

                            <p>
                                <strong>Sobre o Histogram Diff:</strong> esse algoritmo foi introduzido posteriormente
                                no Git como uma evolução do <em>Patience Diff</em>. Ele também busca gerar diffs mais
                                <strong>legíveis</strong>, mas utiliza um método baseado em
                                <strong>histogramas de frequência</strong> para identificar linhas únicas e
                                significativas nos arquivos. Dessa forma, ele equilibra bem a clareza do resultado com
                                uma melhor cobertura de mudanças, sendo especialmente útil em arquivos com muitas
                                repetições de linhas semelhantes. HistogramDiff foi adicionado em 2011 no Git.
                            </p>
                        </div>

                        <div id="hunks" class="about-text">
                            <h1 class="h4 portfolio-title">Deltas e Hunks</h1>
                            <p>
                                Ao executar o comando no Linux: <code>diff old.txt new.txt > changes.patch</code> o
                                sistema vai executar o diff, e criar um novo arquivo (changes.patch) onde estará
                                armazenado o <strong>delta</strong>. O nome "delta" vem da letra grega Δ (delta), usada
                                em matemática para representar mudança ou variação. Nesse caso, podemos dizer que o
                                arquivo <code>changes.patch</code> é o <strong>delta</strong> entre
                                <code>old.txt</code> e <code>new.txt</code>.
                            </p>
                            <p>Segue abaixo um exemplo de conteúdo de um delta:</p>

                            <pre><code>@@ -1,3 +1,3 @@<span style="color: red;">-Linha antiga</span><span style="color: green;">+Linha nova</span>Linha que não mudou</code></pre>

                            <p>
                                Perceba que na primeira linha do arquivo de delta, existe isso:
                                <code>@@ -1,3 +1,3 @@</code> essas informações indicam o "contenxto de mudança", isso é
                                necessário pois um arquivo delta não armazena todo o conteúdo do arquivo original, ele
                                apenas armazena hunks (nacos) de código, e a ferramenta <code>patch</code>, precisa
                                saber examente qual ele deve aplicar as mudanças.
                            </p>
                            <p><code>@@</code>: Cada hunk começa com <code>@@</code> e termina com <code>@@</code>.</p>
                            <p>
                                Você provavelmente já se deparou com algo assim ao visualizar as alterações de um commit
                                no <strong>Git</strong>. Veja o exemplo abaixo:
                            </p>

                            <div class="item item-diagrama">
                                <img
                                    src="../../assets/images/blog/diff-github-example.png"
                                    class="img-expanded"
                                    style="width: 100%"
                                />
                                <div class="item-description">
                                    <small><i>Visualização de um diff no GitHub.</i></small>
                                </div>
                            </div>

                            <br />

                            <p>
                                Quando uma nova linha é adicionada, ela é marcada com o símbolo
                                <small style="color: green">+</small>. Já quando uma linha é removida, ela aparece com o
                                símbolo <small style="color: red">−</small>. Esse é o formato mais comum para arquivos
                                de <em>patch</em>, conhecido como
                                <a
                                    href="https://www.gnu.org/software/diffutils/manual/html_node/Unified-Format.html"
                                    class="blog-link"
                                    target="_blank"
                                    >Unified Format</a
                                >.
                            </p>
                        </div>

                        <div id="lcs" class="about-text">
                            <h1 class="h4 portfolio-title">LCS</h1>

                            <p>
                                A melhor forma de compreender e implementar algoritmos como o <strong>Myers</strong> ou
                                o <strong>Patience</strong> é começar pela sua base: o <strong>LCS clássico</strong>.
                                Entender o problema da LCS e o funcionamento do algoritmo tradicional é essencial para,
                                posteriormente, compreender tanto a solução ótima proposta por Myers quanto a heurística
                                empregada pelo Patience.
                            </p>

                            <p>O problema de LCS pode ser resumido da seguinte forma:</p>

                            <pre><code>Dadas duas sequências, queremos encontrar a maior subsequência que aparece em ambas, 
mantendo a ordem, mas não necessariamente de forma contígua.</code></pre>

                            <p>
                                Vamos imaginar duas listas. Nosso objetivo é descobrir qual é a maior subsequência comum
                                entre <code>Lista_A</code> e <code>Lista_B</code>. Veja o exemplo:
                            </p>

                            <pre><code>Lista_A = A B C D G H
Lista_B = A E D F H R

"A": aparece nas duas → ✅
"D": aparece nas duas, depois de "A" → ✅
"H": aparece nas duas, depois de "D" → ✅

LCS = A D H
</code></pre>

                            <p>Perceba que a LCS encontrada (<code>A D H</code>) respeita as seguintes regras:</p>

                            <p>
                                1. Os elementos aparecem tanto em <code>Lista_A</code> quanto em <code>Lista_B</code> →
                                <i>comum</i> <br /><br />

                                2. Eles mantêm a mesma ordem nas duas listas → <i>subsequência</i> <br /><br />

                                3. <code>A D H</code> é a maior sequência possível que atende às condições anteriores →
                                <i>mais longa</i>
                            </p>

                            <p>
                                Em um algoritmo de <strong>diff de texto</strong>, o papel da LCS é identificar quais
                                linhas <strong>não mudaram</strong> entre o arquivo A e o arquivo B. A partir dessa
                                subsequência comum, o algoritmo consegue determinar quais linhas foram
                                <strong>adicionadas</strong> ou <strong>removidas</strong>.
                            </p>

                            <p>
                                Com base nisso, é gerado o <strong>Shortest Edit Script (SES)</strong>, que representa o
                                conjunto mínimo de operações necessárias para transformar o arquivo A no arquivo B. Cada
                                linha é associada a um tipo de <strong>operação</strong>, são elas:
                            </p>

                            <ul>
                                <li><strong>EQUAL</strong>: linha presente em ambos os arquivos (parte da LCS).</li>
                                <li>
                                    <strong>INSERT</strong> (<small style="color: green">+</small>): linha adicionada em
                                    B.
                                </li>
                                <li>
                                    <strong>DELETE</strong> (<small style="color: red">−</small>): linha removida de A.
                                </li>
                            </ul>

                            <p>Exemplo:</p>

                            <pre><code>Arquivo A:
1. nome = "Alice"
2. idade = 25
3. cidade = "São Paulo"

Arquivo B:
1. nome = "Alice"
2. idade = 26
3. país = "Brasil"
4. cidade = "São Paulo"

LCS: ["nome = 'Alice'", "cidade = 'São Paulo'"]

SES:
  nome = "Alice" → EQUAL
- idade = 25 → DELETE
+ idade = 26 → INSERT
+ país = "Brasil" → INSERT
  cidade = "São Paulo" → EQUAL
</code></pre>

                            <p>
                                Para entender com precisão como obter a operação para cada linha de cada arquivo, a
                                lógica é a seguinte:
                            </p>
                            <pre><code>
Validação para identificar a operação necessária:

Arquivo A:
1. Se essa linha existe na LCS → EQUAL
2. Se essa linha não existe na LCS → DELETE

Arquivo B:
1. Se essa linha existe na LCS → EQUAL
2. Se essa linha não existe na LCS → INSERT

SES EXPLICADO:
  nome = "Alice" → EQUAL, ESSA LINHA EXISTE NA LCS.
- idade = 25 → DELETE, ESSA LINHA NÃO EXISTE NA LCS. (LINHA DO ARQUIVO A)
+ idade = 26 → INSERT, ESSA LINHA NÃO EXISTE NA LCS. (LINHA DO ARQUIVO B)
+ país = "Brasil" → INSERT, ESSA LINHA NÃO EXISTE NA LCS. (LINHA DO ARQUIVO B)
  cidade = "São Paulo" → EQUAL, ESSA LINHA EXISTE NA LCS.
</code></pre>
                            <p>
                                É assim que um diff totalmente baseado no algoritmo de LCS clássico funciona, primeiro
                                identifica o que <strong>não mudou (LCS)</strong> e depois identifica qual é a
                                <strong>operação</strong> necessária para cada linha que <strong>mudou</strong> (SES).
                            </p>
                            <p>
                                Como mencionado anteriormente, o problema dessa abordagem, é que ela é ineficiente para
                                arquivos grandes, com muitas linhas e muitas alterações, mas para entender esse déficit,
                                temos que sair da teoria e ir para o campo prático, e verificar como funciona a
                                construção desse algoritmo.
                            </p>
                            <p>Segue abaixo o algoritmo que obtém a LCS em Rust:</p>

                            <details>
                                <summary>Código fonte do algoritmo LCS</summary>
                                <pre><code>
fn main() {
    println!("Resolvendo o problema da LCS!");
    let entries_a = vec!["A", "G", "G", "T", "A", "B"];
    let entries_b = vec!["G", "X", "T", "X", "A", "Y", "B"]; 

    let mut dp: Vec&lt;Vec&lt;i32&gt;&gt; = vec![vec![0; entries_b.len() + 1]; entries_a.len() + 1];

    for i in 1..=entries_a.len() {
        for j in 1..=entries_b.len()  {
            if entries_a[i-1] == entries_b[j-1] {
                dp[i][j] = dp[i-1][j-1] + 1;
            }
            else {
                dp[i][j] = dp[i-1][j].max(dp[i][j-1]);
            }
        }
    }

    let lcs_len = dp[entries_a.len()][entries_b.len()];
    println!("o tamanho da LCS é: {}", lcs_len);

    let mut i = entries_a.len();
    let mut j = entries_b.len();
    let mut lcs: Vec&lt;&str&gt; = Vec::new();

    while i > 0 && j > 0 {
        if entries_a[i-1] == entries_b[j-1] {
            lcs.push(entries_a[i-1]);
            j -= 1;
            i -= 1;
        }
        else if dp[i-1][j] > dp[i][j-1] {
            i -= 1;
        }
        else {
            j -= 1;
        }
    }

    lcs.reverse();
    println!("LCS completa é: {:?}", lcs);
}
</code></pre>
                            </details>

                            <p>
                                O primeiro <strong>subproblema</strong> que precisamos resolver é: determinar o
                                <strong>tamanho</strong> da LCS. Esse resultado é fundamental, pois será utilizado
                                posteriormente para reconstruir a subsequência comum mais longa em si.
                            </p>

                            <p>
                                Para isso, inicializamos uma matriz <code>dp</code> (<em>dynamic programming</em>)
                                preenchida com zeros. Ela possui tamanho <strong>(m + 1) × (n + 1)</strong>, onde
                                <strong>m</strong> = <code>entries_a.len()</code> (comprimento de <em>A</em>) e
                                <strong>n</strong> = <code>entries_b.len()</code> (comprimento de <em>B</em>).
                            </p>

                            <p>
                                Em seguida, utilizamos dois laços <code>for</code> aninhados para percorrer cada posição
                                da matriz, conforme mostrado abaixo:
                            </p>

                            <pre><code>
for i in 1..=entries_a.len() {
    for j in 1..=entries_b.len() {
        if entries_a[i - 1] == entries_b[j - 1] {
            dp[i][j] = dp[i - 1][j - 1] + 1;
        } else {
            dp[i][j] = dp[i - 1][j].max(dp[i][j - 1]);
        }
    }
}
</code></pre>
                            <p>
                                Essa abordagem tem uma complexidade de tempo de
                                <strong>O(m × n)</strong>, pois cada célula da matriz é visitada exatamente uma vez.
                                Embora eficiente do ponto de vista teórico-polynomial, o custo de armazenamento e
                                processamento pode se tornar elevado para arquivos muito grandes — especialmente nas
                                décadas de 1970 e 1980, quando recursos de memória e CPU eram extremamente limitados.
                            </p>
                            <p>Dentro dos for, existe isso:</p>
                            <pre><code>
if entries_a[i - 1] == entries_b[j - 1] {
    dp[i][j] = dp[i - 1][j - 1] + 1;
} else {
    dp[i][j] = dp[i - 1][j].max(dp[i][j - 1]);
}
</code></pre>
                            <p>
                                Você deve estar se perguntando: "que raios esta acontecendo aqui?". Essa é a parte
                                "mágica" do algoritmo, onde a matemática entra na jogada.
                            </p>
                            <p>A fórmula matemática original é essa:</p>

                            <div class="item item-diagrama">
                                <img
                                    src="../../assets/images/blog/diff-lcs.png"
                                    class="img-expanded"
                                    style="width: 100%"
                                />
                            </div>
                            <br />
                            <p>Fórmula adaptada para programação dinâmica com a matriz <code>dp</code>:</p>

                            <div class="item item-diagrama">
                                <img
                                    src="../../assets/images/blog/diff-lcs-dp.png"
                                    class="img-expanded"
                                    style="width: 100%"
                                />
                            </div>

                            <br />

                            <p>
                                Não vou entrar no detalhe matemático dessas fórmulas, apenas vou mostrar o funcionamento
                                do algoritmo a nivel de programação, caso queira entender essas fórmulas detalhadamente,
                                recomendo esse artigo:
                                <a
                                    href="https://ics.uci.edu/~dhirschb/pubs/p664-hirschberg.pdf"
                                    target="_blank"
                                    class="blog-link"
                                    >Algorithms for the Longest Common Subsequence Problem </a
                                >. Segue abaixo uma explicação da aplicação das fórmulas do algoritmo em pseudocódigo:
                            </p>

                            <code>
                                <pre>
i = Linha
j = Coluna

formula 1: dp[i][j] = dp[i - 1][j - 1] + 1;
formula 2: dp[i - 1][j].max(dp[i][j - 1]); (recebe o maior valor entre "dp[i - 1][j]" e "dp[i][j - 1]")

Quando aplicar cada fórmula:

se entries_a[i - 1] == entries_b[j - 1] → dp[i][j] = dp[i - 1][j - 1] + 1; (fórmula 1)
se não → dp[i - 1][j].max(dp[i][j - 1]); (fórmula 2)
                            </pre
                                >
                            </code>
                            <br />
                            <p>
                                Após percorrer toda a matriz e setar cada célula com o valor obtido pelas
                                <strong>fórmulas</strong>, vamos obter uma matriz <code>dp</code> nesse estilo:
                            </p>
                            <pre><code>
let entries_a = vec!["A", "G", "G", "T", "A", "B"];
let entries_b = vec!["G", "X", "T", "X", "A", "Y", "B"]; 

Matriz dp:

      |   | G | X | T | X | A | Y | B
      | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
  A   | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1
  G   | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1
  G   | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1
  T   | 0 | 1 | 1 | 2 | 2 | 2 | 2 | 2
  A   | 0 | 1 | 1 | 2 | 2 | 3 | 3 | 3
  B   | 0 | 1 | 1 | 2 | 2 | 3 | 3 | 4

</code></pre>
                            <p>
                                Perceba o último valor da última célula da dp, na posição: <code>dp[6][8]</code>, o
                                valor obtido é <strong>4</strong>, esse é o <strong>tamanho da LCS!</strong>
                            </p>
                            <p>
                                Agora, temos que resolver o segundo — e último — subproblema, que é: obter a LCS. Para
                                isso será necessário utilizar a matriz <code>dp</code> que criamos para resolver o
                                problema anterior.
                            </p>
                            <p>Nesse momento, estamos estudando essa parte do algoritmo:</p>
                            <pre><code>
let mut i = entries_a.len();
let mut j = entries_b.len();
let mut lcs: Vec&lt;&str&gt; = Vec::new();

while i > 0 && j > 0 {
    if entries_a[i-1] == entries_b[j-1] {
        lcs.push(entries_a[i-1]);
        j -= 1;
        i -= 1;
    }
    else if dp[i-1][j] > dp[i][j-1] {
        i -= 1;
    }
    else {
        j -= 1;
    }
}

lcs.reverse();
println!("LCS completa é: {:?}", lcs);</code></pre>

                            <p>
                                Nessa etapa do algoritmo ocorre o processo conhecido como <strong>backtracking</strong>.
                                Ele consiste em percorrer a matriz <code>dp</code> de trás para frente — isto é,
                                partindo do último elemento até o primeiro — para reconstruir a subsequência comum mais
                                longa (LCS).
                            </p>
                            <p>
                                A cada iteração, comparamos os caracteres das duas sequências e seguimos o caminho que
                                levou ao valor atual da matriz. Se <code>entries_a[i - 1] == entries_b[j - 1]</code>,
                                significa que esse caractere faz parte da LCS. Ele é adicionado ao resultado, e movemos
                                diagonalmente (<code>i -= 1</code> e <code>j -= 1</code>).
                            </p>
                            <p>
                                Caso contrário, seguimos o maior valor entre <code>dp[i - 1][j]</code> e
                                <code>dp[i][j - 1]</code> — ou seja, avançamos na direção onde há uma subsequência comum
                                mais longa.
                            </p>
                            <p>
                                No fim do processo, obtemos a LCS na ordem inversa, por isso é necessário aplicar
                                <code>lcs.reverse()</code> para recuperar a sequência correta.
                            </p>
                            <p>Veja esse exemplo visual da matriz <code>dp</code> sendo percorrida:</p>

                            <pre><code>
Lógica explicada:
entries_a[i-1] == entries_b[j-1]: Elementos iguais, faz parte da LCS, anda na Diagonal (↖)
dp[i-1][j] > dp[i][j-1]: Elementos diferentes, não faz parte da LCS, anda para cima ↑
dp[i-1][j] > dp[i][j-1]: Elementos diferentes, não faz parte da LCS, anda para esquerda ←

Dp:
      |   | G | X | T | X | A | Y | B
      | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
  A   | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1
  G   | 0 | 1↖| 1 | 1 | 1 | 1 | 1 | 1
  G   | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1
  T   | 0 | 1 | 1 | 2↖| 2 | 2 | 2 | 2
  A   | 0 | 1 | 1 | 2 | 2 | 3↖| 3 | 3
  B   | 0 | 1 | 1 | 2 | 2 | 3 | 3 | 4↖

O backtraking percorreu 4 células diagonais: (6,7) → (5,5) → (4,3) → (2,1)
Cada uma representa um elemento da LCS: G, T, A, B</code></pre>

                            <p>
                                E essa é a explicação geral do algoritmo utilizado pelos diffs baseados no LCS clássico.
                                Vale destacar que o algoritmo de LCS não é aplicado apenas em ferramentas de comparação
                                de texto, mas também é amplamente utilizado em outras áreas, como na
                                <strong>Bioinformática</strong>, especialmente em tarefas de
                                <i>alinhamento de sequências</i> de DNA, RNA e proteínas.
                            </p>

                            <p>
                                Neste tópico, o foco foi explicar o funcionamento do algoritmo de LCS e sua aplicação
                                nos algoritmos de diff. No entanto, não cheguei a implementar um diff baseado
                                diretamente em LCS — até porque esse tipo de abordagem se tornou obsoleta após o
                                surgimento do algoritmo de <strong>Myers</strong>. Assim, concentrei meus esforços no
                                desenvolvimento de uma ferramenta de diff utilizando os algoritmos de
                                <strong>Myers</strong> e <strong>Patience</strong>, que são muito mais eficientes e
                                modernos.
                            </p>
                        </div>

                        <div id="myers" class="about-text">
                            <h1 class="h4 portfolio-title">Myers</h1>

                            <p>
                                Antes de apresentar o algoritmo completo de <strong>Myers Diff</strong>, é importante
                                compreender que, apesar de o algoritmo de Myers ter surgido a partir do problema
                                clássico da <strong>LCS</strong> (Longest Common Subsequence), ele possui um
                                <strong>objetivo diferente</strong>. Enquanto o LCS tradicional busca identificar
                                diretamente a subsequência comum mais longa entre dois textos, o Myers tem como foco
                                encontrar o <strong>Shortest Edit Script (SES)</strong> — ou seja, a menor sequência de
                                operações necessárias para transformar o arquivo A no arquivo B.
                            </p>

                            <p>
                                Em ferramentas de diff baseadas no algoritmo clássico de <strong>LCS</strong>, o
                                processo ocorre em duas etapas: primeiro é extraída a LCS entre os textos e, em seguida,
                                é calculado o <strong>Shortest Edit Script (SES)</strong> a partir dela. Já no algoritmo
                                de <strong>Myers</strong>, essa lógica é invertida — o <strong>SES</strong> é obtido
                                diretamente, sem a necessidade de calcular previamente a LCS.
                            </p>

                            <p>
                                Embora o algoritmo de Myers tenha sido inspirado no LCS clássico, seu objetivo principal
                                não é encontrar a LCS, mas sim o conjunto mínimo de operações de edição entre dois
                                textos. Ainda assim, é possível derivar a LCS de forma opcional, já que as relações
                                matemáticas entre o SES e a LCS são equivalentes.
                            </p>

                            <p>
                                Em resumo, o algoritmo de Myers não constrói toda a matriz <code>dp</code> para calcular
                                o tamanho da LCS. Em vez disso, ele percorre apenas as
                                <strong>diagonais possíveis</strong> — os caminhos mais promissores dentro da matriz de
                                comparação — e a partir dessas diagonais determina diretamente o <strong>SES</strong>.
                                Como consequência, a <strong>LCS</strong> pode ser obtida indiretamente, simplesmente
                                observando as operações de <code>MATCH</code> encontradas no script de edição.
                            </p>

                            <p>
                                No LCS clássico, cada célula da matriz é visitada, resultando em uma complexidade de
                                <code>O(m × n)</code> tanto em tempo quanto em memória, onde <code>m</code> e
                                <code>n</code> são os tamanhos das sequências comparadas. Já o algoritmo de Myers
                                otimiza esse processo ao reduzir o custo temporal para <code>O(N × D)</code>, sendo
                                <code>N</code> o tamanho do menor arquivo e <code>D</code> o número mínimo de edições
                                (inserções ou deleções) necessárias. Além disso, o consumo de memória cai para
                                <code>O(N + D)</code>. Essa abordagem torna o Myers muito mais eficiente, especialmente
                                em textos grandes ou quando as diferenças entre as versões são pequenas.
                            </p>

                            <p>
                                Veja esse exemplo do algoritmo Myers em Rust (utilizando as mesmas strings dos exemplos
                                da LCS):
                            </p>

                            <details>
                                <summary>Código fonte do algoritmo MYERS</summary>
                                <pre><code>
fn main() {
    println!("Resolvendo o problema do Myers!");

    let entries_a = vec!["A", "G", "G", "T", "A", "B"];
    let entries_b = vec!["G", "X", "T", "X", "A", "Y", "B"];

    let n = entries_a.len();
    let m = entries_b.len();

    let max = (n + m) as usize;
    let offset = max;

    let mut v: Vec&lt;isize&gt; = vec![0; 2 * max + 1];
    let mut trace: Vec&lt;Vec&lt;isize&gt;&gt; = Vec::new();

    for d in 0..=max as isize {
        let mut y = 0;
        let mut x = 0;

        for k in (-d..=d).step_by(2) {
            let k_idx = (k + offset as isize) as usize;

            x = if k == -d || (k != d && v[(k - 1 + offset as isize) as usize] < v[(k + 1 + offset as isize) as usize]) {
                v[(k + 1 + offset as isize) as usize]
            } else {
                v[(k - 1 + offset as isize) as usize] + 1
            };

            y = x - k;

            while x < n as isize && y < m as isize && entries_a[x as usize] == entries_b[y as usize] {
                x += 1;
                y += 1;
            }

            v[k_idx] = x;

            if (x as usize) >= n && (y as usize) >= m {
                println!("Tamanho mínimo do SES (D): {}", d);
                trace.push(v.clone());
                break;
            }
        }

        if (x as usize) >= n && (y as usize) >= m {
            break;
        }

        trace.push(v.clone());
    }

    let mut x = n as isize;
    let mut y = m as isize;

    // SES invertido
    let mut edits: Vec&lt;String&gt; = Vec::new();

    for (d, v) in trace.iter().enumerate().rev() {
        let k = x - y;
        let d_isize = d as isize;

        let prev_k = if k == -d_isize
            || (k != d_isize
                && v[(k - 1 + offset as isize) as usize] < v[(k + 1 + offset as isize) as usize])
        {
            k + 1
        } else {
            k - 1
        };

        let prev_x = v[(prev_k + offset as isize) as usize];
        let prev_y = prev_x - prev_k;

        // MATCHES — parte da LCS
        while x > prev_x && y > prev_y {
            edits.push(format!("MATCH {}", entries_a[(x - 1) as usize]));
            x -= 1;
            y -= 1;
        }

        if d > 0 {
            if y > 0 && x == prev_x {
                edits.push(format!("INSERT {}", entries_b[(y - 1) as usize]));
                y -= 1;
            } else if x > 0 {
                edits.push(format!("DELETE {}", entries_a[(x - 1) as usize]));
                x -= 1;
            }
        }
    }

    let mut lcs: Vec&lt;&str&gt; = Vec::new();

    for op in edits.iter().rev() {
        if op.starts_with("MATCH") {
            let value = op.split_whitespace().nth(1).unwrap();
            lcs.push(value);
        }
    }

    println!("\nTamanho da LCS: {}", lcs.len());
    println!("LCS completa: {:?}", lcs);
}

</code></pre>
                            </details>

                            <p>
                                O algoritmo de Myers inicia percorrendo o espaço de edição em diagonais, representando
                                todas as possíveis diferenças entre as duas sequências. Em vez de construir uma matriz
                                completa como no LCS clássico, ele utiliza apenas um vetor <code>v</code> que armazena o
                                ponto mais distante alcançado em cada diagonal para um determinado número de edições
                                <code>d</code>. Essa abordagem permite explorar caminhos de forma incremental,
                                expandindo apenas as diagonais relevantes e ignorando áreas redundantes. A cada iteração
                                de <code>d</code>, o algoritmo tenta avançar o máximo possível em direções de "match"
                                (caracteres iguais), formando uma espécie de “caminho” eficiente dentro do grid de
                                comparação.
                            </p>

                            <p>
                                Exemplo visual simples de como o Myers percorre a matriz <code>dp</code> pelas
                                <strong>diagonais</strong>:
                            </p>

                            <pre>
                                <code>
entries_a = [A, G, G, T, A, B]
entries_b = [G, X, T, X, A, Y, B]

      G   X   T   X   A   Y   B
   +---+---+---+---+---+---+---+
A  | \ |   |   |   |   |   |   |
   +---+---+---+---+---+---+---+
G  | ↑ | \ |   |   |   |   |   |
   +---+---+---+---+---+---+---+
G  |   | ↑ | \ |   |   |   |   |
   +---+---+---+---+---+---+---+
T  |   |   | ↑ | \ |   |   |   |
   +---+---+---+---+---+---+---+
A  |   |   |   | ↑ | \ |   |   |
   +---+---+---+---+---+---+---+
B  |   |   |   |   | ↑ | \ | ✓ |
   +---+---+---+---+---+---+---+
                                </code>
                            </pre>
                            <p>
                                Durante a expansão, o algoritmo armazena o estado do vetor <code>v</code> em cada
                                iteração dentro de uma estrutura de rastreamento (<code>trace</code>). Essa fase é
                                essencial para reconstruir posteriormente o caminho exato das edições mínimas (a
                                Shortest Edit Script - SES). Cada posição salva em <code>trace</code> representa uma
                                "foto" do progresso do algoritmo em um determinado número de edições, permitindo que o
                                backtracking seja feito de forma eficiente sem recalcular as diagonais.
                            </p>
                            <p>
                                Quando o algoritmo encontra um caminho que cobre ambas as sequências (<code>x ≥ n</code>
                                e <code>y ≥ m</code>), inicia-se o processo inverso: o <strong>backtracking</strong>. A
                                partir do estado final armazenado em <code>trace</code>, o algoritmo volta pelas
                                iterações, reconstruindo as operações que levaram à transformação da sequência A em B.
                                Nessa etapa são identificadas as operações de inserção, deleção e correspondência
                                (matches), compondo o conjunto mínimo de edições. Além disso, a sequência de
                                correspondências define implicitamente a Longest Common Subsequence (LCS), que pode ser
                                extraída diretamente do resultado.
                            </p>
                            <p>
                                Por fim, o algoritmo imprime ou retorna o resultado do diff: a sequência de edições
                                (SES) e, opcionalmente, a LCS. Essa saída pode ser utilizada tanto para visualizar as
                                diferenças entre duas versões de um texto quanto para análises mais complexas, como
                                fusão de branches em sistemas de controle de versão. Essa abordagem garante alta
                                eficiência, com complexidade de tempo e espaço <code>O(N + D²)</code> em sua forma
                                básica, ou <code>O(ND)</code> em versões otimizadas — significativamente melhor do que o
                                <code>O(N × M)</code> do LCS clássico.
                            </p>

                            <p>
                                Segue o código completo do sistema diff que eu implementei que utiliza o algoritmo do
                                Myers, separei o código em uma biblioteca (crate lib). Veja:
                            </p>
                            <details>
                                <summary>Código fonte do sistema Myers-Diff</summary>
                                <pre><code>
use utils::{DiffOp};

pub fn remove_comum_prefix_and_suffix<'a>(
    a: &'a [&'a str],
    b: &'a [&'a str],
) -> (&'a [&'a str], &'a [&'a str], &'a [&'a str], &'a [&'a str]) {
    let mut start = 0;
    let mut end_a = a.len();
    let mut end_b = b.len();

    while start < end_a && start < end_b && a[start] == b[start] {
        start += 1;
    }

    while end_a > start && end_b > start && a[end_a - 1] == b[end_b - 1] {
        end_a -= 1;
        end_b -= 1;
    }

    let prefix = &a[..start];
    let mid_a = &a[start..end_a];
    let mid_b = &b[start..end_b];
    let suffix = &a[end_a..];

    return (prefix, mid_a, mid_b, suffix)
}

pub fn myers_diff&lt;'a&gt;(content_a: &'a [&'a str], content_b: &'a [&'a str]) -> Vec&lt;DiffOp&lt;'a&gt;&gt; {
    let (prefix, mid_a, mid_b, suffix_a) = remove_comum_prefix_and_suffix(content_a, content_b);

    let n = mid_a.len();
    let m = mid_b.len();
    let max = (n + m) as usize;
    let offset = max;

    let trace = forward(max, offset, n, m, mid_a, mid_b);
    let mut edits: Vec&lt;DiffOp&lt;'a&gt;&gt; = Vec::new();
    
    for line in prefix {
        edits.push(DiffOp::Match(line));
    }

    edits.extend(backtracking(trace, offset, n, m, mid_a, mid_b));

    for line in suffix_a {
        edits.push(DiffOp::Match(line));
    }
    
    edits
}

// Short Edit Script (SES)
fn forward(
    max: usize,
    offset: usize,
    n: usize,
    m: usize,
    content_a: &[&str],
    content_b: &[&str]
) -> Vec&lt;(isize, Vec&lt;isize&gt;)&gt; {
    let mut v: Vec&lt;isize&gt; = vec![0; 2 * max + 1];
    let mut trace: Vec&lt;(isize, Vec&lt;isize&gt;)&gt; = Vec::new();

    for d in 0..=max as isize {
        trace.push((d, v.clone()));

        for k in (-d..=d).step_by(2) {
            let k_idx = (k + offset as isize) as usize;

            let mut x = if k == -d || (k != d && v[(k-1+offset as isize) as usize] < v[(k+1+offset as isize) as usize])
            {
                v[(k+1+offset as isize) as usize]
            } else {
                v[(k-1+offset as isize) as usize] + 1
            };

            let mut y = x - k;

            while (x as usize) < n && (y as usize) < m && content_a[x as usize] == content_b[y as usize] {
                x += 1;
                y += 1;
            }

            v[k_idx] = x;

            if (x as usize) >= n && (y as usize) >= m {
                break;
            }
        }
    }

    trace
}

// Traceback
fn backtracking&lt;'a&gt;(
    trace: Vec&lt;(isize, Vec&lt;isize&gt;)>,
    offset: usize,
    n: usize,
    m: usize,
    content_a: &'a [&'a str],
    content_b: &'a [&'a str],
) -> Vec&lt;DiffOp&lt;'a&gt;&gt; {
    let mut edits: Vec&lt;DiffOp&lt;'a&gt;&gt; = Vec::new();
    let mut x = n as isize;
    let mut y = m as isize;

    for (d, v) in trace.iter().rev() {
        let d = *d as isize;
        let k = x - y;

        let prev_k = if k == -d
            || (k != d && v[(k - 1 + offset as isize) as usize] < v[(k + 1 + offset as isize) as usize])
        {
            k + 1
        } else {
            k - 1
        };

        let prev_x = v[(prev_k + offset as isize) as usize];
        let prev_y = prev_x - prev_k;

        while x > prev_x && y > prev_y {
            edits.insert(0, DiffOp::Match(content_a[(x - 1) as usize]));   
            x -= 1;
            y -= 1;
        }

        if x == prev_x && y > prev_y {
            if y > 0 {
                edits.insert(0, DiffOp::Insert(content_b[(y - 1) as usize]));
            }
            y -= 1;
        }
        else if x > prev_x && y == prev_y {
            if x > 0 {
                edits.insert(0, DiffOp::Delete(content_a[(x - 1) as usize]));
            }
            x -= 1;
        }
    }

    edits
}
</code></pre>
                            </details>
                        </div>

                        <div id="patience" class="about-text">
                            <h1 class="h4 portfolio-title">Patience</h1>
                            <p>
                                O objetivo do Patience é outro: Gerar deltas mais legiveis para humanos. O foco do
                                patience é aparencia e não perfomance. Para isso ele implementa o algoritmo
                                <strong>LIS (Longest Increasing Subsequence)</strong>, funciona muito bem para arquivos
                                de textos com poucas alteração ou arquivos que possuem muitas linhas em comum, mas para
                                casos extremos, como arquivos com muitas mudançás e diferenças, ele recorre ao algoritmo
                                do Myers como fallback.
                            </p>
                            <p>
                                Para entender como o Patience-diff funciona e como ele gera deltas mais legiveis,
                                primeiro devemos entender como funciona o algoritmo <strong>LIS</strong> e qual o
                                objetivo disso.
                            </p>
                            <p>
                                A diferença do LIS para LCS é só uma: <strong>ordenação</strong>, como visto
                                anteriormente, a LCS não necessária mente precisa ser ordenada, ou seja, é possivel
                                encontrar a LCS de um texto com linhas elementos não ordenados, exemplo:
                            </p>

                            <pre><code>
Sequência A: [3, 9, 8, 3, 9, 7, 9, 7, 0]
Sequência B: [3, 3, 9, 9, 9, 1, 7, 2, 0]

LCS = [3, 9, 9, 7, 0]

Note que os números não estão em ordem crescente, mas respeitam a ordem em que aparecem nas duas listas.</code></pre>
                            <br />

                            <p>Exemplo da LIS:</p>
                            <pre><code>
Sequência: [10, 22, 9, 33, 21, 50, 41, 60]

LIS = [10, 22, 33, 50, 60]

Note que os números estão em ordem crescente, além de respeitar a ordem em que aparecem nas duas listas os elementos estão ordenados.</code></pre>
                            <p>Segue abaixo o algoritmo da LIS:</p>

                            <details>
                                <summary>Código fonte do algoritmo LIS</summary>
                                <pre><code>
fn main() {
    println!("Resolvendo o problema da LIS!");

    let entries = vec![10, 22, 9, 33, 21, 50, 41, 60];
    let mut tails: Vec&lt;i32&gt; = Vec::new();
    let mut indices: Vec&lt;usize&gt; = Vec::new();
    let mut prev_index: Vec&lt;Option&lt;usize&gt;&gt; = vec![None; entries.len()];

    for (index, entry) in entries.iter().enumerate() {
        let pos = match tails.binary_search(entry) {
            Ok(pos) => pos,
            Err(pos) => pos
        };

        if pos == tails.len() {    
            tails.push(*entry);
            indices.push(index);
        }
        else {
            tails[pos] = *entry;
            indices[pos] = index;
        }

        if pos == 0 {
            prev_index[index] = None;
        }
        else {
            prev_index[index] = Some(indices[pos - 1]);
        }
    }

    let mut last_index: Option&lt;usize&gt; = Some(indices[tails.len() - 1]);
    let mut lis: Vec&lt;i32&gt; = Vec::new();

    while last_index != None {
        let i = last_index.unwrap();
        lis.push(entries[i]);

        last_index = prev_index[i];
    }

    lis.reverse();

    println!("Tails:");
    for tail in tails {
        print!("{}", tail);
    }
    
    println!("\nIndices:");
    for idx in &indices {
        print!("{}", idx);
    }

    println!("\nLis:");
    for index in lis {
        print!("{}", index);
    }
}
</code></pre>
                            </details>

                            <p>
                                Diferente do algoritmo LCS, a LIS não lida com matriz, o problema da Longest Increasing
                                subsequence é resolvido com o uso de 3 arrays auxiliares, são eles:
                            </p>

                            <p>
                                <code>Tails:</code> <br />

                                Armazena o menor elemento possível para cada comprimento de subsequência crescente. Ou
                                seja, tails[k] guarda o menor valor que pode terminar uma subsequência crescente de
                                tamanho (k + 1). Isso permite decidir rapidamente (via busca binária) onde inserir o
                                próximo elemento.
                            </p>

                            <p>
                                <code>Indices:</code> <br />
                                Guarda os índices correspondentes aos elementos dentro de 'tails' no vetor original.
                                Eles servem para reconstruir o caminho (a subsequência completa) ao final do algoritmo.
                            </p>

                            <p>
                                <code>prev_index:</code> <br />
                                Armazena, para cada posição do vetor original, o índice do elemento anterior na
                                subsequência crescente. Esse vetor é usado na reconstrução final da LIS, percorrendo de
                                trás para frente até formar toda a sequência.
                            </p>
                            <p>Veja como fica o estado de cada array no loop principal do algoritmo:</p>
                            <details>
                                <summary>Simulação visual do algoritmo LIS</summary>
                                <pre>
                                <code>
entries = [10, 22, 9, 33, 21, 50, 41, 60]

Iteração 0 ─ entry = 10
tails       = [10]
indices     = [0]
prev_index  = [None, None, None, None, None, None, None, None]

Iteração 1 ─ entry = 22
tails       = [10, 22]
indices     = [0, 1]
prev_index  = [None, Some(0), None, None, None, None, None, None]

Iteração 2 ─ entry = 9
tails       = [9, 22]
indices     = [2, 1]
prev_index  = [None, Some(0), None, None, None, None, None, None]

Iteração 3 ─ entry = 33
tails       = [9, 22, 33]
indices     = [2, 1, 3]
prev_index  = [None, Some(0), None, Some(1), None, None, None, None]

Iteração 4 ─ entry = 21
tails       = [9, 21, 33]
indices     = [2, 4, 3]
prev_index  = [None, Some(0), None, Some(1), Some(2), None, None, None]

Iteração 5 ─ entry = 50
tails       = [9, 21, 33, 50]
indices     = [2, 4, 3, 5]
prev_index  = [None, Some(0), None, Some(1), Some(2), Some(3), None, None]

Iteração 6 ─ entry = 41
tails       = [9, 21, 33, 41]
indices     = [2, 4, 3, 6]
prev_index  = [None, Some(0), None, Some(1), Some(2), Some(3), Some(3), None]

Iteração 7 ─ entry = 60
tails       = [9, 21, 33, 41, 60]
indices     = [2, 4, 3, 6, 7]
prev_index  = [None, Some(0), None, Some(1), Some(2), Some(3), Some(3), Some(6)]

----------------------------------------------------
Reconstrução:
Começando de last_index = indices[4] = 7

prev_index encadeia:
7 → 6 → 3 → 1 → 0

LIS (reverso): [60, 41, 33, 22, 10]
LIS final: [10, 22, 33, 41, 60]</code>
                            </pre>
                            </details>

                            <p>
                                No Patience-diff, o algoritmo LIS é utilizado para obter as <strong>âncoras</strong>.
                                Âncoras são linhas que aparecem em ambas as versões do texto <em>na mesma ordem</em> e
                                que, portanto, servem como pontos de referência estáveis para alinhar as diferenças.
                            </p>

                            <p>
                                Em outras palavras, as âncoras representam a
                                <strong>subsequência crescente mais longa (LIS)</strong>
                                das linhas que são únicas e coincidem entre os dois arquivos. Essas linhas formam uma
                                base sólida sobre a qual o restante do diff é construído, melhorando a legibilidade do
                                resultado final.
                            </p>

                            <p>
                                Após identificar as âncoras, o algoritmo divide o problema em blocos menores: cada
                                trecho entre duas âncoras é tratado recursivamente, aplicando novamente o mesmo processo
                                de correspondência e comparação. Dessa forma, o Patience Diff combina precisão e
                                clareza, produzindo um diff mais legível que o gerado por algoritmos puramente baseados
                                em LCS.
                            </p>

                            <p>
                                Resumidamente, o diff é aplicado <strong>ENTRE</strong> as âncoras, veja esse exemplo de
                                detecção de âncoras para entender:
                            </p>

                            <pre><code>
Exemplo:
Texto A:
1: fn main() {
2:   println!("Olá");
3:   println!("Mundo");
4: }

Texto B:
1: fn main() {
2:   println!("Mundo");
3:   println!("!");
4: }

Âncoras (LIS sobre as linhas únicas e comuns):
[ "fn main() {", "println!(\"Mundo\");", "}" ]

Essas linhas servem como delimitadores fixos para o algoritmo,
ajudando a identificar de forma eficiente quais trechos mudaram
entre as âncoras.
</code></pre>

                            <p>
                                Se em algum momento do processo de comparação nenhuma <strong>âncora</strong> for
                                encontrada, isso indica que os arquivos possuem muitas diferenças ou não há linhas
                                únicas que possam servir de referência estável. Nesses casos, o
                                <strong>Patience Diff</strong> utiliza o algoritmo <strong>Myers</strong> como
                                estratégia de fallback para continuar o cálculo das diferenças.
                            </p>

                            <p>
                                Para visualizar as diferenças de um delta gerado pelo Patience e um delta gerado pelo
                                Myers, voce pode ver isso no
                                <a href="https://bramcohen.livejournal.com/73318.html" target="_blank" class="blog-link"
                                    >Blog do Bram cohen</a
                                >
                                .
                            </p>

                            <p>
                                Segue abaixo o código fonte completo do patience diff utilizando o algoritmo
                                <strong>LIS</strong>, separei o código em uma biblioteca (crate lib). Veja:
                            </p>

                            <details>
                                <summary>Código fonte do sistema Patience-Diff</summary>
                                <pre><code>
use std::collections::HashMap;

use myers::myers_diff;
use utils::DiffOp;

pub fn patience_diff&lt;'a&gt;(content_a: &'a [&'a str], content_b: &'a [&'a str]) -> Vec&lt;DiffOp&lt;'a&gt;&gt; {
    let anchors = find_unique_anchors(content_a, content_b);

    if anchors.is_empty() {
        return myers_diff(content_a, content_b);
    }

    let positions_b: Vec&lt;usize&gt; = anchors.iter().map(|(_, _, idx_b)| *idx_b).collect();
    let lis_idx = get_lis_indices(&positions_b);
    let anchors_final: Vec&lt;_&gt; = lis_idx.iter().map(|&i| anchors[i]).collect();

    let mut diff = Vec::new();
    let mut last_a = 0;
    let mut last_b = 0;

    for &(anchor_line, idx_a, idx_b) in &anchors_final {
        let sub_a = &content_a[last_a..idx_a];
        let sub_b = &content_b[last_b..idx_b];

        if !sub_a.is_empty() || !sub_b.is_empty() {
            diff.extend(myers_diff(sub_a, sub_b));
        }

        diff.push(DiffOp::Match(anchor_line));

        last_a = idx_a + 1;
        last_b = idx_b + 1;
    }

    let sub_a = &content_a[last_a..];
    let sub_b = &content_b[last_b..];
    if !sub_a.is_empty() || !sub_b.is_empty() {
        diff.extend(myers_diff(sub_a, sub_b));
    }

    diff
}

fn find_unique_anchors&lt;'a&gt;(content_a: &'a [&'a str], content_b: &'a [&'a str]) -> Vec&lt;(&'a str, usize, usize)&gt; {
    let unique_a = get_unique_lines(content_a);
    let unique_b = get_unique_lines(content_b);

    let mut anchors = Vec::new();
    for &line in content_a.iter() {
        if let (Some(&idx_a), Some(&idx_b)) = (unique_a.get(line), unique_b.get(line)) {
            anchors.push((line, idx_a, idx_b));
        }
    }

    anchors
}

fn get_unique_lines&lt;'a&gt;(content_lines: &'a [&'a str]) -> HashMap&lt;&'a str, usize&gt; {
    let mut freq = HashMap::with_capacity(content_lines.len());
    let mut result = HashMap::with_capacity(content_lines.len());

    for (i, &line) in content_lines.iter().enumerate() {
        let count = freq.entry(line).or_insert(0);
        *count += 1;

        if *count == 1 {
            result.insert(line, i);
        } else {
            result.remove(line);
        }
    }

    result
}

fn get_lis_indices(seq: &[usize]) -> Vec&lt;usize&gt; {
    if seq.is_empty() {
        return Vec::new();
    }

    let mut tails_vals = Vec::with_capacity(seq.len());
    let mut tails_indices = Vec::with_capacity(seq.len());
    let mut predecessors = vec![None; seq.len()];

    for (i, &x) in seq.iter().enumerate() {
        let pos = tails_vals.binary_search(&x).unwrap_or_else(|p| p);

        if pos == tails_vals.len() {
            tails_vals.push(x);
            tails_indices.push(i);
        } else {
            tails_vals[pos] = x;
            tails_indices[pos] = i;
        }

        if pos > 0 {
            predecessors[i] = Some(tails_indices[pos - 1]);
        }
    }

    let mut lis = Vec::new();
    if let Some(&last_index) = tails_indices.last() {
        let mut k = Some(last_index);
        while let Some(idx) = k {
            lis.push(idx);
            k = predecessors[idx];
        }
        lis.reverse();
    }

    lis
}</code></pre>
                            </details>
                        </div>

                        <div id="conclusion" class="about-text">
                            <h1 class="h4 portfolio-title">Conclusão</h1>

                            <p>
                                Esse foi um breve resumo dos principais algoritmos de diff, aprendi bastante sobre
                                algoritmos e programação dinâmica. Esses algoritmos são excelentes para quem está
                                estudando algoritmo e estruta de dados na faculdade.
                            </p>

                            <p>
                                Perceba que eu me concentrei muito em descrever o funcionamento do algoritmo clássico do
                                LCS, fiz isso pois, esse algoritmo além de ser o primeiro a ser utilizado em ferramentas
                                de diff, também é a base dos demais que vieram a seguir: Myers e Patience.
                            </p>

                            <p>
                                Depois de implementar esses dois diffs com Rust, eu exportei ele como
                                <code>dll</code> para utiliza-lo no <strong>gitAdr</strong>, criando assim um novo
                                comando: <code>gitadr diff</code>.
                            </p>
                        </div>

                        <div id="conclusion" class="about-text">
                            <h1 class="h4 portfolio-title">Conclusão</h1>

                            <p>
                                Esse foi um breve resumo dos principais algoritmos de diff, aprendi bastante sobre
                                algoritmos e programação dinâmica. Esses algoritmos são excelentes para quem está
                                estudando algoritmo e estruta de dados na faculdade.
                            </p>

                            <p>
                                Perceba que eu me concentrei muito em descrever o funcionamento do algoritmo clássico do
                                LCS, fiz isso pois, esse algoritmo além de ser o primeiro a ser utilizado em ferramentas
                                de diff, também é a base dos demais que vieram a seguir: Myers e Patience.
                            </p>

                            <p>
                                Depois de implementar esses dois diffs com Rust, eu exportei ele como
                                <code>dll</code> para utiliza-lo no <strong>gitAdr</strong>, criando assim um novo
                                comando: <code>gitadr diff</code>.
                            </p>
                        </div>

                        <div id="refs" class="blog-text">
                            <h1 class="h4 portfolio-title">Referências</h1>
                            <ul class="list-decimal list-inside space-y-1">
                                <li>
                                    <a
                                        href="https://ics.uci.edu/~dhirschb/pubs/p664-hirschberg.pdf"
                                        target="_blank"
                                        class="blog-link"
                                        >Algorithms for the Longest Common Subsequence Problem — Artigo PDF </a
                                    >.
                                </li>
                                <li>
                                    <a
                                        href="https://en.wikipedia.org/wiki/Longest_common_subsequence"
                                        target="_blank"
                                        class="blog-link"
                                        >Longest common subsequence (LCS) — Wikipedia</a
                                    >
                                </li>
                                <li>
                                    <a href="http://www.xmailserver.org/diff2.pdf" class="blog-link" target="_blank">
                                        An O(ND) Difference Algorithm and Its Variations — Artigo PDF
                                    </a>
                                </li>
                                <li>
                                    <a
                                        href="https://en.wikipedia.org/wiki/Edit_distance"
                                        class="blog-link"
                                        target="_blank"
                                        >Shortest Edit Script (SES) — Wikipedia</a
                                    >
                                </li>
                                <li>
                                    <a
                                        href="https://www.gnu.org/software/diffutils/manual"
                                        class="blog-link"
                                        target="_blank"
                                        >GNU diffutils - Comparing and Merging Files — GNU manual</a
                                    >
                                </li>
                                <li>
                                    <a
                                        href="https://blog.jcoglan.com/2017/09/19/the-patience-diff-algorithm"
                                        class="blog-link"
                                        target="_blank"
                                    >
                                        The patience diff algorithm — James coglan
                                    </a>
                                </li>
                                <li>
                                    <a
                                        href="https://blog.jcoglan.com/2017/02/12/the-myers-diff-algorithm-part-1"
                                        class="blog-link"
                                        target="_blank"
                                    >
                                        The Myers diff algorithm — James coglan
                                    </a>
                                </li>
                                <li>
                                    <a
                                        href="https://bramcohen.livejournal.com/73318.html"
                                        target="_blank"
                                        class="blog-link"
                                        >Patience Diff Advantages — Bram cohen</a
                                    >
                                </li>
                                <li>
                                    <a href="https://git-scm.com/docs/git-diff" target="_blank" class="blog-link"
                                        >Git diff — Git docs</a
                                    >
                                </li>
                                <li>
                                    <a
                                        href="https://ably.com/blog/practical-guide-to-diff-algorithms"
                                        target="_blank"
                                        class="blog-link"
                                        >The definitive guide to diff algorithms and patch formats — Ably</a
                                    >
                                </li>
                            </ul>
                        </div>
                    </section>
                </article>
            </div>
        </main>

        <script type="module" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script>
        <script nomodule src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"></script>
        <script type="module" src="../../../assets/js/index.js"></script>
        <script type="module">
            import { loadSideBarBlog } from '../../assets/js/elements/sidebar.js';

            const sections = [
                { id: 'intro', label: 'Introdução' },
                { id: 'history', label: 'Estudar o passado é compreender o presente' },
                { id: 'hunks', label: 'Deltas e Hunks' },
                { id: 'lcs', label: 'LCS' },
                { id: 'myers', label: 'Myers' },
                { id: 'patience', label: 'Patience' },
                { id: 'conclusion', label: 'Conclusão' },
                { id: 'refs', label: 'Referências' }
            ];

            loadSideBarBlog(sections);
        </script>
    </body>
</html>
